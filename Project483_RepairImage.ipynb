{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Project483-RepairImage",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries"
   ],
   "metadata": {
    "id": "6WJxzVQfHzub"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "99FTKsx6NPXf"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Import and Data Preprocessing "
   ],
   "metadata": {
    "id": "SmmVaOQcHSxl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#import Dataset Library \n",
    "#Files to be processed\n",
    "\n",
    "        #from google.colab import drive\n",
    "        #drive.mount('/content/gdrive')\n",
    "\n"
   ],
   "metadata": {
    "id": "tgjOEpha3ZcE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fc5fa6f-7897-4526-e02d-d84db6705565"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Import images to read \n",
    "\n",
    "#folder = os.path.join('/content/drive/My Drive/epoch100')\n",
    "import os\n",
    "os.getcwd()\n",
    "#collection = '/content/drive/My_Drive/epoch100/'\n",
    "collection_damage = \"C:/Users/mechanika/Dropbox/School/CPSC 483 Machine Learning/Project-Main/project-main/epoch100/seg_test\"\n",
    "collection_ori = \"C:/Users/mechanika/Dropbox/School/CPSC 483 Machine Learning/Project-Main/project-main/epoch100/seg_pred\"\n",
    "\n",
    "for i, filename in enumerate(os.listdir(collection_damage)):\n",
    "   damaged_images = cv2.imread(\"a\"+str(i)+\".png\")\n",
    "\n",
    "for i, filename in enumerate(os.listdir(collection_ori)):\n",
    "   ori_images = cv2.imread(\"a\"+str(i)+\".png\")"
   ],
   "metadata": {
    "id": "-xR84H7rNWit",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "outputId": "373c1a85-7a53-4dd7-da09-3b43c9a56871"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Data Preprocessing through Normalization\n",
    "#This is used to normalize an image which converts the RGB data of an image into a range of integers\n",
    "\n",
    "for i, filename in enumerate(os.listdir(collection_damage)):\n",
    "    gray_images = damaged_images.color.rgb2gray(damaged_images)\n",
    "    norm_image = (gray_images - np.min(gray_images)) / (np.max(gray_images) - np.min(gray_images))\n"
   ],
   "metadata": {
    "id": "pu00yRru31xm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "outputId": "f836a227-719b-4f49-f3bc-bdea08d0d460"
   },
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'color'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MECHAN~1\\AppData\\Local\\Temp/ipykernel_13168/4260042480.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilename\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcollection_damage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mgray_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdamaged_images\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrgb2gray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdamaged_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mnorm_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mgray_images\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgray_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgray_images\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgray_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'color'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Data using an ML algorithm"
   ],
   "metadata": {
    "id": "GwaJyQRbHdyv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Read mask\n",
    "#expand this by bringing on perhaps Clustering?\n",
    "#certainly not KNN\n",
    "mask_path = \"Mask.tiff\"\n",
    "mask = cv2.imread(mask_path, 0)"
   ],
   "metadata": {
    "id": "p6KT2OVYNYaO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Data by fixing the Images\n"
   ],
   "metadata": {
    "id": "LXKlHVGeHkvC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Use cv2 to read and fix the damaged image\n",
    "damaged_images = cv2.cvtColor(damaged_images, cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "id": "-4gC_WAiNaTz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#print both the mask and the fixed image\n",
    "output1 = cv2.inpaint(damaged_image, mask, 1, cv2.INPAINT_TELEA)\n",
    "output2 = cv2.inpaint(damaged_image, mask, 1, cv2.INPAINT_NS)"
   ],
   "metadata": {
    "id": "8Xy2fVhsNb5r"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "DXBOtPW9MICG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Show Before and After Restoration\n"
   ],
   "metadata": {
    "id": "eXl5vtopHp9d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#show plot\n",
    "img = [damaged_image, mask, output1, output2]\n",
    "titles = ['damaged image', 'mask', 'TELEA', 'NS']\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(titles[i])\n",
    "    plt.imshow(img[i])\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "sVYPIBdvNdiL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Predictions and Confusion Matrix\n"
   ],
   "metadata": {
    "id": "BlUgbVadHvWM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#confusion matrix\n",
    "#this is supposed to show the accuracy of algorithm\n",
    "cm = metrics.confusion_matrix(test_imgs, ori_images)\n",
    "ax = sns.heatmap(cm, annot=True, \n",
    "                 xticklabels = use_cats,\n",
    "                 yticklabels = use_cats,\n",
    "                 fmt='3d')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')"
   ],
   "metadata": {
    "id": "Idt3szNnH6V8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}